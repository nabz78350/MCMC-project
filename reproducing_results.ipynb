{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from utils import * \n",
    "from grid_search_parallelized import GAN,Generator,Discriminator,Params\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data_train_log_return.csv'\n",
    "header = [\"stock1\", \"stock2\", \"stock3\", \"stock4\"]\n",
    "df_train = pd.read_csv(file_path, header=None,index_col=0)\n",
    "df_train.columns = header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock1</th>\n",
       "      <th>stock2</th>\n",
       "      <th>stock3</th>\n",
       "      <th>stock4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008924</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>0.009693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029719</td>\n",
       "      <td>0.023891</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>0.019281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016568</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.012109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031298</td>\n",
       "      <td>0.058209</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.007062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028111</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.034699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.014071</td>\n",
       "      <td>0.037233</td>\n",
       "      <td>0.006712</td>\n",
       "      <td>0.009907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>0.004527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.017424</td>\n",
       "      <td>0.018642</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.002421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.035604</td>\n",
       "      <td>0.014567</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.020795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.015251</td>\n",
       "      <td>0.016035</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.012614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stock1    stock2    stock3    stock4\n",
       "0    0.008924  0.001562  0.008722  0.009693\n",
       "1    0.029719  0.023891  0.018772  0.019281\n",
       "2    0.016568  0.004815  0.006206  0.012109\n",
       "3    0.031298  0.058209  0.002368  0.007062\n",
       "4    0.028111  0.008061  0.004144  0.034699\n",
       "..        ...       ...       ...       ...\n",
       "405  0.014071  0.037233  0.006712  0.009907\n",
       "406  0.006035  0.001339  0.009284  0.004527\n",
       "407  0.017424  0.018642  0.003280  0.002421\n",
       "408  0.035604  0.014567  0.005901  0.020795\n",
       "409  0.015251  0.016035  0.003433  0.012614\n",
       "\n",
       "[410 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"submission/model_params.json\", \"r\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "    latent_dim = config['latent_dim']\n",
    "    g_config = config['generator']\n",
    "    d_config = config['discriminator']\n",
    "\n",
    "opt = Params()  # Assuming Params is a class that contains other GAN parameters\n",
    "opt.latent_dim = latent_dim \n",
    "opt.n_epochs =0 ## model weights are already trained\n",
    "\n",
    "def generate_noise(n_samples):\n",
    "    # Create covariance matrix with 1 on the diagonal and random values for non-diagonal elements\n",
    "    covariance_matrix= 0.75 ** np.abs(np.subtract.outer ( np.arange(opt.latent_dim),np.arange (opt.latent_dim)))\n",
    "    noise = np.random.multivariate_normal(mean=np.zeros(opt.latent_dim),\n",
    "                                            cov=covariance_matrix,\n",
    "                                            size=n_samples)\n",
    "    squared_noise = noise**2\n",
    "    cube_noise = noise **3\n",
    "    noise = np.concatenate([noise, squared_noise,cube_noise], axis=1)\n",
    "    return noise\n",
    "\n",
    "## build GAN\n",
    "generator = Generator(latent_dim,output_shape = opt.shape_data, **g_config)\n",
    "\n",
    "### load weigths\n",
    "generator.model.load_weights('submission/generator_weights.h5')\n",
    "discriminator = Discriminator(opt.shape_data,**d_config)\n",
    "gan = GAN(generator,discriminator,opt)\n",
    "\n",
    "\n",
    "### import noise\n",
    "noise = pd.read_csv('submission/noise.csv',index_col=0)\n",
    "noise = noise.values\n",
    "synthetic_data = generator.model.predict(noise)\n",
    "synthetic_data = pd.DataFrame(synthetic_data,columns = df_train.columns) /100\n",
    "synthetic_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
