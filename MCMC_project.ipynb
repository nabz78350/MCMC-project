{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from grid_search_parallelized import GAN,Generator, Discriminator, Params\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "IMAGES_PATH = 'images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data_train_log_return.csv'\n",
    "header = [\"stock1\", \"stock2\", \"stock3\", \"stock4\"]\n",
    "df_train = pd.read_csv(file_path, header=None,index_col=0)\n",
    "df_train.columns = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.describe().to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting distribution and correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix  = df_train.cov()\n",
    "correlation_matrix = df_train.corr()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "\n",
    "# Iterate through columns and plot for each subplot\n",
    "for i, column_name in enumerate(df_train.columns):\n",
    "    row_index = i // 2\n",
    "    col_index = i % 2\n",
    "    sns.histplot(df_train[column_name], kde=True, label='Original Data',stat = 'density', color='blue', alpha=0.5, ax=axes[row_index, col_index])\n",
    "    axes[row_index, col_index].set_title(f'{column_name} Distribution')\n",
    "    axes[row_index, col_index].set_xlabel(column_name)\n",
    "    axes[row_index, col_index].legend()\n",
    "\n",
    "  \n",
    "fig.savefig(IMAGES_PATH+'true_data_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, fmt='.2f', annot=True, cmap=sns.diverging_palette(h_neg=20, h_pos=220), center=0)\n",
    "plt.title('Original data - Log returns correlation')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Saving the plot\n",
    "plt.savefig(IMAGES_PATH + 'true_data_correlation_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analytical solution using cholesky decomposition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "synthetic_data = cholesky(df_train.shape[0],cov_matrix)\n",
    "synthetic_data = pd.DataFrame(synthetic_data,columns = df_train.columns)\n",
    "synthetic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "\n",
    "# Iterate through columns and plot for each subplot\n",
    "for i, column_name in enumerate(df_train.columns):\n",
    "    row_index = i // 2\n",
    "    col_index = i % 2\n",
    "    sns.histplot(df_train[column_name], kde=True, label='Original Data',stat = 'density', color='blue', alpha=0.5, ax=axes[row_index, col_index])\n",
    "    sns.histplot(synthetic_data[column_name], kde=True, label='Synthetic Data',stat = 'density', color='orange', alpha=0.5, ax=axes[row_index, col_index])\n",
    "    axes[row_index, col_index].set_title(f'{column_name} Distribution')\n",
    "    axes[row_index, col_index].set_xlabel(column_name)\n",
    "    axes[row_index, col_index].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(IMAGES_PATH+'cholesky_synthetic_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(synthetic_data.corr(), \n",
    "            fmt='.2f',\n",
    "            annot=True,\n",
    "            cmap=sns.diverging_palette(h_neg=20,\n",
    "                                          h_pos=220), center=0).set(title='synthetic data - Log returns correlation')\n",
    "plt.tight_layout()\n",
    "# Saving the plot\n",
    "plt.savefig(IMAGES_PATH + 'cholesky_synthetic_correlation_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Flatten the axis array for easy iteration\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, column in enumerate(df_train.columns):\n",
    "    # Compute CDFs\n",
    "    x_train, y_train = compute_cdf(df_train[column])\n",
    "    x_synthetic, y_synthetic = compute_cdf(synthetic_data[column])\n",
    "\n",
    "    # Plot CDFs\n",
    "    axs[i].plot(x_train, y_train, label='True Distribution', color='blue')\n",
    "    axs[i].plot(x_synthetic, y_synthetic, label='Synthetic Distribution', color='red')\n",
    "\n",
    "    axs[i].set_title(f'CDF of {column}')\n",
    "    axs[i].set_xlabel('Value')\n",
    "    axs[i].set_ylabel('CDF')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(IMAGES_PATH + 'cholesky_cdf_synthetic_correlation_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = []\n",
    "kendall = []\n",
    "test_size = 410\n",
    "for i in tqdm(range(200)):\n",
    "    test_sample = df_train.sample(test_size)\n",
    "    cov_matrix_sample = test_sample.cov()\n",
    "    synthetic_data = cholesky(test_size,cov_matrix_sample)\n",
    "    ad.append(AndersonDarling(synthetic_data,test_sample.values))\n",
    "    kendall.append(kendall_tau_distance(pd.DataFrame(synthetic_data,columns =test_sample.columns),test_sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations = pd.DataFrame({'AndersonDarling':ad,'Kendall':kendall})\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "df = pd.DataFrame({'AndersonDarling': ad, 'Kendall': kendall})\n",
    "\n",
    "# Creating subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "\n",
    "# Plotting histogram for AndersonDarling values\n",
    "axes[0].hist(df['AndersonDarling'], bins=20, edgecolor='black')\n",
    "axes[0].set_title('Histogram of Anderson-Darling Test Results')\n",
    "axes[0].set_xlabel('Anderson-Darling Statistic')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Plotting histogram for Kendall values\n",
    "axes[1].hist(df['Kendall'], bins=20, edgecolor='black')\n",
    "axes[1].set_title('Histogram of Kendall Tau Distance Results')\n",
    "axes[1].set_xlabel('Kendall Tau Distance')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "# Adjusting layout and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig.savefig(IMAGES_PATH + 'cholesky_iterations_metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gaussian mixture models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iterations = 200\n",
    "n_components = 10\n",
    "best_anderling = 1e6\n",
    "best_kendall = 1e6\n",
    "best_weights = None\n",
    "for i in tqdm(range(iterations)):\n",
    "    train, test = train_test_split(df_train, test_size=0.6, random_state=i)\n",
    "    train.reset_index(drop=True,inplace=True)\n",
    "    test.reset_index(drop=True,inplace=True)\n",
    "    if best_weights is None :\n",
    "        gmm = GaussianMixture(n_components=n_components,\n",
    "                        covariance_type=  \"full\",\n",
    "                        weights_init= best_weights)\n",
    "    else :\n",
    "        GaussianMixture(n_components=n_components,\n",
    "                        covariance_type=  \"full\")\n",
    "        \n",
    "    gmm.fit(train)\n",
    "\n",
    "\n",
    "    # Generating new samples\n",
    "    synthetic_data,_  = gmm.sample(test.shape[0])  # Generate 10 new samples\n",
    "    synthetic_data = pd.DataFrame(synthetic_data,columns = test.columns)\n",
    "    distance = AndersonDarling(test.values, synthetic_data.values)\n",
    "    kendall = kendall_tau_distance(test,synthetic_data)\n",
    "    if distance < best_anderling:\n",
    "        print('new best', distance)\n",
    "        best_anderling = distance\n",
    "        best_kendall = kendall\n",
    "        best_weights = gmm.weights_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data,_ = gmm.sample(df_train.shape[0])\n",
    "synthetic_data = pd.DataFrame(synthetic_data,columns = df_train.columns.tolist())\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Flatten the axis array for easy iteration\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, column in enumerate(df_train.columns):\n",
    "    # Compute CDFs\n",
    "    x_train, y_train = compute_cdf(df_train[column])\n",
    "    x_synthetic, y_synthetic = compute_cdf(synthetic_data[column])\n",
    "\n",
    "    # Plot CDFs\n",
    "    axs[i].plot(x_train, y_train, label='True Distribution', color='blue')\n",
    "    axs[i].plot(x_synthetic, y_synthetic, label='Synthetic Distribution', color='red')\n",
    "\n",
    "    axs[i].set_title(f'CDF of {column}')\n",
    "    axs[i].set_xlabel('Value')\n",
    "    axs[i].set_ylabel('CDF')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(IMAGES_PATH + 'GMM_cdf_synthetic_correlation_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = []\n",
    "kendall = []\n",
    "test_size = 410\n",
    "for i in tqdm(range(200)):\n",
    "    test_sample = df_train.sample(test_size)\n",
    "    synthetic_data,_ = gmm.sample(test_size)\n",
    "    ad.append(AndersonDarling(synthetic_data,test_sample.values))\n",
    "    kendall.append(kendall_tau_distance(pd.DataFrame(synthetic_data,columns =test_sample.columns),test_sample))\n",
    "\n",
    "simulations = pd.DataFrame({'AndersonDarling':ad,'Kendall':kendall})\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "df = pd.DataFrame({'AndersonDarling': ad, 'Kendall': kendall})\n",
    "\n",
    "# Creating subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "\n",
    "# Plotting histogram for AndersonDarling values\n",
    "axes[0].hist(df['AndersonDarling'], bins=20, edgecolor='black')\n",
    "axes[0].set_title('Histogram of Anderson-Darling Test Results')\n",
    "axes[0].set_xlabel('Anderson-Darling Statistic')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Plotting histogram for Kendall values\n",
    "axes[1].hist(df['Kendall'], bins=20, edgecolor='black')\n",
    "axes[1].set_title('Histogram of Kendall Tau Distance Results')\n",
    "axes[1].set_xlabel('Kendall Tau Distance')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "# Adjusting layout and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig.savefig(IMAGES_PATH + 'GMM_iterations_metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "synthetic_data,_ = gmm.sample(df_train.shape[0])\n",
    "synthetic_data = pd.DataFrame(synthetic_data,columns = df_train.columns)\n",
    "feature_names = df_train.columns\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "\n",
    "# Iterate through columns and plot for each subplot\n",
    "for i, column_name in enumerate(df_train.columns):\n",
    "    row_index = i // 2\n",
    "    col_index = i % 2\n",
    "    sns.histplot(df_train[column_name], kde=True, label='Original Data',stat = 'density', color='blue', alpha=0.5, ax=axes[row_index, col_index])\n",
    "    sns.histplot(synthetic_data[column_name], kde=True, label='Synthetic Data',stat = 'density', color='orange', alpha=0.5, ax=axes[row_index, col_index])\n",
    "    axes[row_index, col_index].set_title(f'{column_name} Distribution')\n",
    "    axes[row_index, col_index].set_xlabel(column_name)\n",
    "    axes[row_index, col_index].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(IMAGES_PATH+'GMM_synthetic_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(synthetic_data.corr(), \n",
    "            fmt='.2f',\n",
    "            annot=True,\n",
    "            cmap=sns.diverging_palette(h_neg=20,\n",
    "                                          h_pos=220), center=0).set(title='GMM synthetic data - Log returns correlation')\n",
    "plt.tight_layout()\n",
    "# Saving the plot\n",
    "plt.savefig(IMAGES_PATH + 'GMM_synthetic_correlation_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(synthetic_data.describe().to_latex(\n",
    "\n",
    "    \n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GAN Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g_number_layer</th>\n",
       "      <th>g_number_neuron</th>\n",
       "      <th>g_hidden_activation</th>\n",
       "      <th>g_output_activation</th>\n",
       "      <th>d_number_layer</th>\n",
       "      <th>d_number_neuron</th>\n",
       "      <th>d_hidden_activation</th>\n",
       "      <th>d_output_activation</th>\n",
       "      <th>latent_dim</th>\n",
       "      <th>mean_anderling_distance</th>\n",
       "      <th>mean_kendall_tau</th>\n",
       "      <th>Combination</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Generator_16_relu_softplus_Discriminator_8_relu_softplus_LatentDim_100</th>\n",
       "      <td>1</td>\n",
       "      <td>[16]</td>\n",
       "      <td>['relu']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1</td>\n",
       "      <td>[8]</td>\n",
       "      <td>['relu']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>100</td>\n",
       "      <td>1.146847</td>\n",
       "      <td>0.074504</td>\n",
       "      <td>Generator_16_relu_softplus_Discriminator_8_rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generator_16_softplus_16_softplus_softplus_Discriminator_16_softplus_16_softplus_sigmoid_LatentDim_20</th>\n",
       "      <td>2</td>\n",
       "      <td>[16, 16]</td>\n",
       "      <td>['softplus', 'softplus']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2</td>\n",
       "      <td>[16, 16]</td>\n",
       "      <td>['softplus', 'softplus']</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>20</td>\n",
       "      <td>39.332153</td>\n",
       "      <td>0.159008</td>\n",
       "      <td>Generator_16_softplus_16_softplus_softplus_Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generator_8_leaky_relu_8_leaky_relu_softplus_Discriminator_64_leaky_relu_softplus_LatentDim_50</th>\n",
       "      <td>2</td>\n",
       "      <td>[8, 8]</td>\n",
       "      <td>['leaky_relu', 'leaky_relu']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1</td>\n",
       "      <td>[64]</td>\n",
       "      <td>['leaky_relu']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>50</td>\n",
       "      <td>7.404184</td>\n",
       "      <td>0.045845</td>\n",
       "      <td>Generator_8_leaky_relu_8_leaky_relu_softplus_D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generator_32_leaky_relu_softplus_Discriminator_8_softplus_8_softplus_sigmoid_LatentDim_100</th>\n",
       "      <td>1</td>\n",
       "      <td>[32]</td>\n",
       "      <td>['leaky_relu']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2</td>\n",
       "      <td>[8, 8]</td>\n",
       "      <td>['softplus', 'softplus']</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>2.324328</td>\n",
       "      <td>0.036774</td>\n",
       "      <td>Generator_32_leaky_relu_softplus_Discriminator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generator_64_softplus_64_softplus_softplus_Discriminator_8_softplus_8_softplus_softplus_LatentDim_20</th>\n",
       "      <td>2</td>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>['softplus', 'softplus']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2</td>\n",
       "      <td>[8, 8]</td>\n",
       "      <td>['softplus', 'softplus']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>20</td>\n",
       "      <td>25.638776</td>\n",
       "      <td>0.097676</td>\n",
       "      <td>Generator_64_softplus_64_softplus_softplus_Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generator_64_relu_64_relu_softplus_Discriminator_64_softplus_softplus_LatentDim_20</th>\n",
       "      <td>2</td>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>['relu', 'relu']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1</td>\n",
       "      <td>[64]</td>\n",
       "      <td>['softplus']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>20</td>\n",
       "      <td>11.646904</td>\n",
       "      <td>0.041475</td>\n",
       "      <td>Generator_64_relu_64_relu_softplus_Discriminat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generator_32_softplus_32_softplus_softplus_Discriminator_32_relu_32_relu_sigmoid_LatentDim_100</th>\n",
       "      <td>2</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>['softplus', 'softplus']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2</td>\n",
       "      <td>[32, 32]</td>\n",
       "      <td>['relu', 'relu']</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>10.142577</td>\n",
       "      <td>0.093360</td>\n",
       "      <td>Generator_32_softplus_32_softplus_softplus_Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generator_64_softplus_softplus_Discriminator_8_leaky_relu_sigmoid_LatentDim_100</th>\n",
       "      <td>1</td>\n",
       "      <td>[64]</td>\n",
       "      <td>['softplus']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1</td>\n",
       "      <td>[8]</td>\n",
       "      <td>['leaky_relu']</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>69.971989</td>\n",
       "      <td>0.057828</td>\n",
       "      <td>Generator_64_softplus_softplus_Discriminator_8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generator_8_relu_softplus_Discriminator_64_leaky_relu_64_leaky_relu_sigmoid_LatentDim_20</th>\n",
       "      <td>1</td>\n",
       "      <td>[8]</td>\n",
       "      <td>['relu']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>2</td>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>['leaky_relu', 'leaky_relu']</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>20</td>\n",
       "      <td>35.413362</td>\n",
       "      <td>0.057346</td>\n",
       "      <td>Generator_8_relu_softplus_Discriminator_64_lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generator_64_softplus_64_softplus_softplus_Discriminator_8_softplus_softplus_LatentDim_20</th>\n",
       "      <td>2</td>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>['softplus', 'softplus']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>1</td>\n",
       "      <td>[8]</td>\n",
       "      <td>['softplus']</td>\n",
       "      <td>softplus</td>\n",
       "      <td>20</td>\n",
       "      <td>56.742621</td>\n",
       "      <td>0.101814</td>\n",
       "      <td>Generator_64_softplus_64_softplus_softplus_Dis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    g_number_layer   \n",
       "name                                                                 \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...               1  \\\n",
       "Generator_16_softplus_16_softplus_softplus_Disc...               2   \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...               2   \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...               1   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...               2   \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...               2   \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...               2   \n",
       "Generator_64_softplus_softplus_Discriminator_8_...               1   \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...               1   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...               2   \n",
       "\n",
       "                                                   g_number_neuron   \n",
       "name                                                                 \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...            [16]  \\\n",
       "Generator_16_softplus_16_softplus_softplus_Disc...        [16, 16]   \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...          [8, 8]   \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...            [32]   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...        [64, 64]   \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...        [64, 64]   \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...        [32, 32]   \n",
       "Generator_64_softplus_softplus_Discriminator_8_...            [64]   \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...             [8]   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...        [64, 64]   \n",
       "\n",
       "                                                             g_hidden_activation   \n",
       "name                                                                               \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...                      ['relu']  \\\n",
       "Generator_16_softplus_16_softplus_softplus_Disc...      ['softplus', 'softplus']   \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...  ['leaky_relu', 'leaky_relu']   \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...                ['leaky_relu']   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...      ['softplus', 'softplus']   \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...              ['relu', 'relu']   \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...      ['softplus', 'softplus']   \n",
       "Generator_64_softplus_softplus_Discriminator_8_...                  ['softplus']   \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...                      ['relu']   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...      ['softplus', 'softplus']   \n",
       "\n",
       "                                                   g_output_activation   \n",
       "name                                                                     \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...            softplus  \\\n",
       "Generator_16_softplus_16_softplus_softplus_Disc...            softplus   \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...            softplus   \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...            softplus   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...            softplus   \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...            softplus   \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...            softplus   \n",
       "Generator_64_softplus_softplus_Discriminator_8_...            softplus   \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...            softplus   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...            softplus   \n",
       "\n",
       "                                                    d_number_layer   \n",
       "name                                                                 \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...               1  \\\n",
       "Generator_16_softplus_16_softplus_softplus_Disc...               2   \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...               1   \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...               2   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...               2   \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...               1   \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...               2   \n",
       "Generator_64_softplus_softplus_Discriminator_8_...               1   \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...               2   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...               1   \n",
       "\n",
       "                                                   d_number_neuron   \n",
       "name                                                                 \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...             [8]  \\\n",
       "Generator_16_softplus_16_softplus_softplus_Disc...        [16, 16]   \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...            [64]   \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...          [8, 8]   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...          [8, 8]   \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...            [64]   \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...        [32, 32]   \n",
       "Generator_64_softplus_softplus_Discriminator_8_...             [8]   \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...        [64, 64]   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...             [8]   \n",
       "\n",
       "                                                             d_hidden_activation   \n",
       "name                                                                               \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...                      ['relu']  \\\n",
       "Generator_16_softplus_16_softplus_softplus_Disc...      ['softplus', 'softplus']   \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...                ['leaky_relu']   \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...      ['softplus', 'softplus']   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...      ['softplus', 'softplus']   \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...                  ['softplus']   \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...              ['relu', 'relu']   \n",
       "Generator_64_softplus_softplus_Discriminator_8_...                ['leaky_relu']   \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...  ['leaky_relu', 'leaky_relu']   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...                  ['softplus']   \n",
       "\n",
       "                                                   d_output_activation   \n",
       "name                                                                     \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...            softplus  \\\n",
       "Generator_16_softplus_16_softplus_softplus_Disc...             sigmoid   \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...            softplus   \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...             sigmoid   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...            softplus   \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...            softplus   \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...             sigmoid   \n",
       "Generator_64_softplus_softplus_Discriminator_8_...             sigmoid   \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...             sigmoid   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...            softplus   \n",
       "\n",
       "                                                    latent_dim   \n",
       "name                                                             \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...         100  \\\n",
       "Generator_16_softplus_16_softplus_softplus_Disc...          20   \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...          50   \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...         100   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...          20   \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...          20   \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...         100   \n",
       "Generator_64_softplus_softplus_Discriminator_8_...         100   \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...          20   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...          20   \n",
       "\n",
       "                                                    mean_anderling_distance   \n",
       "name                                                                          \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...                 1.146847  \\\n",
       "Generator_16_softplus_16_softplus_softplus_Disc...                39.332153   \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...                 7.404184   \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...                 2.324328   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...                25.638776   \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...                11.646904   \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...                10.142577   \n",
       "Generator_64_softplus_softplus_Discriminator_8_...                69.971989   \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...                35.413362   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...                56.742621   \n",
       "\n",
       "                                                    mean_kendall_tau   \n",
       "name                                                                   \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...          0.074504  \\\n",
       "Generator_16_softplus_16_softplus_softplus_Disc...          0.159008   \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...          0.045845   \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...          0.036774   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...          0.097676   \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...          0.041475   \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...          0.093360   \n",
       "Generator_64_softplus_softplus_Discriminator_8_...          0.057828   \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...          0.057346   \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...          0.101814   \n",
       "\n",
       "                                                                                          Combination  \n",
       "name                                                                                                   \n",
       "Generator_16_relu_softplus_Discriminator_8_relu...  Generator_16_relu_softplus_Discriminator_8_rel...  \n",
       "Generator_16_softplus_16_softplus_softplus_Disc...  Generator_16_softplus_16_softplus_softplus_Dis...  \n",
       "Generator_8_leaky_relu_8_leaky_relu_softplus_Di...  Generator_8_leaky_relu_8_leaky_relu_softplus_D...  \n",
       "Generator_32_leaky_relu_softplus_Discriminator_...  Generator_32_leaky_relu_softplus_Discriminator...  \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...  Generator_64_softplus_64_softplus_softplus_Dis...  \n",
       "Generator_64_relu_64_relu_softplus_Discriminato...  Generator_64_relu_64_relu_softplus_Discriminat...  \n",
       "Generator_32_softplus_32_softplus_softplus_Disc...  Generator_32_softplus_32_softplus_softplus_Dis...  \n",
       "Generator_64_softplus_softplus_Discriminator_8_...  Generator_64_softplus_softplus_Discriminator_8...  \n",
       "Generator_8_relu_softplus_Discriminator_64_leak...  Generator_8_relu_softplus_Discriminator_64_lea...  \n",
       "Generator_64_softplus_64_softplus_softplus_Disc...  Generator_64_softplus_64_softplus_softplus_Dis...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def aggregate_results(results_dir='results_old'):\n",
    "#     all_results = []\n",
    "#     # Loop through each combination folder in the results directory\n",
    "#     for combi_name in tqdm(os.listdir(results_dir)):\n",
    "#         combi_dir = os.path.join(results_dir, combi_name)\n",
    "#         if os.path.isdir(combi_dir):\n",
    "#             csv_file = os.path.join(combi_dir, 'results.csv')\n",
    "#             if os.path.exists(csv_file):\n",
    "#                 # Read the CSV file and append it to the list\n",
    "#                 df = pd.read_csv(csv_file)\n",
    "#                 df['Combination'] = combi_name  # Optionally, add a column indicating the combination\n",
    "#                 all_results.append(df)\n",
    "\n",
    "#     # Concatenate all dataframes into one\n",
    "#     df =  pd.concat(all_results, ignore_index=True)\n",
    "#     df = df.sort_values(by ='mean_anderling_distance')\n",
    "#     return df\n",
    "\n",
    "\n",
    "# results = aggregate_results('results').set_index('name')\n",
    "# results.to_csv('submission/grid_search_results.csv')\n",
    "# results.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best model params has been moved to the folder submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generator': {'num_layers': 1,\n",
       "  'neurons_per_layer': [16],\n",
       "  'hidden_activation': ['relu'],\n",
       "  'output_activation': 'softplus'},\n",
       " 'discriminator': {'num_layers': 1,\n",
       "  'neurons_per_layer': [64],\n",
       "  'hidden_activation': ['leaky_relu'],\n",
       "  'output_activation': 'sigmoid'},\n",
       " 'latent_dim': 100}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"submission/model_params.json\", \"r\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "    latent_dim = config['latent_dim']\n",
    "    g_config = config['generator']\n",
    "    d_config = config['discriminator']\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = Params()  \n",
    "opt.latent_dim = latent_dim \n",
    "opt.n_epochs =0 ## model weights are already trained\n",
    "\n",
    "def generate_noise(n_samples):\n",
    "    # Create covariance matrix with 1 on the diagonal and random values for non-diagonal elements\n",
    "    covariance_matrix= 0.75 ** np.abs(np.subtract.outer ( np.arange(opt.latent_dim),np.arange (opt.latent_dim)))\n",
    "    noise = np.random.multivariate_normal(mean=np.zeros(opt.latent_dim),\n",
    "                                            cov=covariance_matrix,\n",
    "                                            size=n_samples)\n",
    "    squared_noise = noise**2\n",
    "    cube_noise = noise **3\n",
    "    noise = np.concatenate([noise, squared_noise,cube_noise], axis=1)\n",
    "    return noise\n",
    "\n",
    "## build GAN\n",
    "generator = Generator(latent_dim,output_shape = opt.shape_data, **g_config)\n",
    "\n",
    "### load weigths\n",
    "generator.model.load_weights('submission/generator_weights.h5')\n",
    "discriminator = Discriminator(opt.shape_data,**d_config)\n",
    "gan = GAN(generator,discriminator,opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = generate_noise(df_train.shape[0])\n",
    "synthetic_data_gan = generator.model.predict(noise)\n",
    "synthetic_data_gan = pd.DataFrame(synthetic_data_gan,columns = df_train.columns)\n",
    "synthetic_data_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Flatten the axis array for easy iteration\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, column in enumerate(df_train.columns):\n",
    "    # Compute CDFs\n",
    "    x_train, y_train = compute_cdf(df_train[column]*100)\n",
    "    x_synthetic, y_synthetic = compute_cdf(synthetic_data_gan[column])\n",
    "\n",
    "    # Plot CDFs\n",
    "    axs[i].plot(x_train, y_train, label='True Distribution', color='blue')\n",
    "    axs[i].plot(x_synthetic, y_synthetic, label='Synthetic Distribution', color='red')\n",
    "\n",
    "    axs[i].set_title(f'CDF of {column}')\n",
    "    axs[i].set_xlabel('Value')\n",
    "    axs[i].set_ylabel('CDF')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig(IMAGES_PATH + 'GAN_cdf_synthetic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = []\n",
    "kendall = []\n",
    "test_size = 410\n",
    "for i in tqdm(range(200)):\n",
    "    test_sample = df_train.sample(test_size)\n",
    "    cov_matrix_sample = test_sample.cov()\n",
    "    synthetic_data = cholesky(test_size,cov_matrix_sample)\n",
    "    ad.append(AndersonDarling(synthetic_data,test_sample.values))\n",
    "    kendall.append(kendall_tau_distance(pd.DataFrame(synthetic_data,columns =test_sample.columns),test_sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = []\n",
    "kendall = []\n",
    "test_size = 410\n",
    "for i in tqdm(range(200)):\n",
    "    test_sample = df_train.sample(test_size) *100\n",
    "    noise = generate_noise(test_size)\n",
    "    synthetic_data = generator.model.predict(noise)\n",
    "\n",
    "    ad.append(AndersonDarling(synthetic_data,test_sample.values))\n",
    "    kendall.append(kendall_tau_distance(pd.DataFrame(synthetic_data,columns =test_sample.columns),test_sample))\n",
    "\n",
    "simulations = pd.DataFrame({'AndersonDarling':ad,'Kendall':kendall})\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "df = pd.DataFrame({'AndersonDarling': ad, 'Kendall': kendall})\n",
    "\n",
    "# Creating subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "\n",
    "# Plotting histogram for AndersonDarling values\n",
    "axes[0].hist(df['AndersonDarling'], bins=20, edgecolor='black')\n",
    "axes[0].set_title('Histogram of Anderson-Darling Test Results')\n",
    "axes[0].set_xlabel('Anderson-Darling Statistic')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Plotting histogram for Kendall values\n",
    "axes[1].hist(df['Kendall'], bins=20, edgecolor='black')\n",
    "axes[1].set_title('Histogram of Kendall Tau Distance Results')\n",
    "axes[1].set_xlabel('Kendall Tau Distance')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "# Adjusting layout and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig.savefig(IMAGES_PATH + 'GAN_iterations_metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = generate_noise(df_train.shape[0])\n",
    "synthetic_data_gan = generator.model.predict(noise)\n",
    "synthetic_data_gan = pd.DataFrame(synthetic_data_gan,columns = df_train.columns)\n",
    "synthetic_data_gan\n",
    "feature_names = df_train.columns\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "\n",
    "# Iterate through columns and plot for each subplot\n",
    "for i, column_name in enumerate(df_train.columns):\n",
    "    row_index = i // 2\n",
    "    col_index = i % 2\n",
    "    sns.histplot(df_train[column_name]*100, kde=True, label='Original Data',stat = 'density', color='blue', alpha=0.5, ax=axes[row_index, col_index])\n",
    "    sns.histplot(synthetic_data_gan[column_name], kde=True, label='Synthetic Data',stat = 'density', color='orange', alpha=0.5, ax=axes[row_index, col_index])\n",
    "    axes[row_index, col_index].set_title(f'{column_name} Distribution')\n",
    "    axes[row_index, col_index].set_xlabel(column_name)\n",
    "    axes[row_index, col_index].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(IMAGES_PATH+'GAN_synthetic_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(synthetic_data_gan.corr(), \n",
    "            fmt='.2f',\n",
    "            annot=True,\n",
    "            cmap=sns.diverging_palette(h_neg=20,\n",
    "                                          h_pos=220), center=0).set(title='synthetic data - Log returns correlation')\n",
    "plt.tight_layout()\n",
    "# Saving the plot\n",
    "plt.savefig(IMAGES_PATH + 'GAN_synthetic_correlation_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2 = 410\n",
    "noise = generate_noise(n2)\n",
    "synthetic_data_gan = generator.model.predict(noise)\n",
    "synthetic_data_gan = pd.DataFrame(synthetic_data_gan,columns = df_train.columns) /100\n",
    "compare(synthetic_data_gan,df_train.sample(n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = pd.DataFrame(noise)\n",
    "noise.to_csv('submission/noise.csv')\n",
    "noise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_gan.to_csv('submission/synthetic_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock1</th>\n",
       "      <th>stock2</th>\n",
       "      <th>stock3</th>\n",
       "      <th>stock4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008924</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.008722</td>\n",
       "      <td>0.009693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029719</td>\n",
       "      <td>0.023891</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>0.019281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016568</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.012109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031298</td>\n",
       "      <td>0.058209</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.007062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028111</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.034699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.014071</td>\n",
       "      <td>0.037233</td>\n",
       "      <td>0.006712</td>\n",
       "      <td>0.009907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.009284</td>\n",
       "      <td>0.004527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.017424</td>\n",
       "      <td>0.018642</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.002421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.035604</td>\n",
       "      <td>0.014567</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.020795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.015251</td>\n",
       "      <td>0.016035</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.012614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stock1    stock2    stock3    stock4\n",
       "0    0.008924  0.001562  0.008722  0.009693\n",
       "1    0.029719  0.023891  0.018772  0.019281\n",
       "2    0.016568  0.004815  0.006206  0.012109\n",
       "3    0.031298  0.058209  0.002368  0.007062\n",
       "4    0.028111  0.008061  0.004144  0.034699\n",
       "..        ...       ...       ...       ...\n",
       "405  0.014071  0.037233  0.006712  0.009907\n",
       "406  0.006035  0.001339  0.009284  0.004527\n",
       "407  0.017424  0.018642  0.003280  0.002421\n",
       "408  0.035604  0.014567  0.005901  0.020795\n",
       "409  0.015251  0.016035  0.003433  0.012614\n",
       "\n",
       "[410 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data_train_log_return.csv'\n",
    "header = [\"stock1\", \"stock2\", \"stock3\", \"stock4\"]\n",
    "df_train = pd.read_csv(file_path, header=None,index_col=0)\n",
    "df_train.columns = header\n",
    "\n",
    "\n",
    "with open(\"submission/model_params.json\", \"r\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "    latent_dim = config['latent_dim']\n",
    "    g_config = config['generator']\n",
    "    d_config = config['discriminator']\n",
    "\n",
    "opt = Params()  # Assuming Params is a class that contains other GAN parameters\n",
    "opt.latent_dim = latent_dim \n",
    "opt.n_epochs =0 ## model weights are already trained\n",
    "\n",
    "def generate_noise(n_samples):\n",
    "    # Create covariance matrix with 1 on the diagonal and random values for non-diagonal elements\n",
    "    covariance_matrix= 0.75 ** np.abs(np.subtract.outer ( np.arange(opt.latent_dim),np.arange (opt.latent_dim)))\n",
    "    noise = np.random.multivariate_normal(mean=np.zeros(opt.latent_dim),\n",
    "                                            cov=covariance_matrix,\n",
    "                                            size=n_samples)\n",
    "    squared_noise = noise**2\n",
    "    cube_noise = noise **3\n",
    "    noise = np.concatenate([noise, squared_noise,cube_noise], axis=1)\n",
    "    return noise\n",
    "\n",
    "## build GAN\n",
    "generator = Generator(latent_dim,output_shape = opt.shape_data, **g_config)\n",
    "\n",
    "### load weigths\n",
    "generator.model.load_weights('submission/generator_weights.h5')\n",
    "discriminator = Discriminator(opt.shape_data,**d_config)\n",
    "gan = GAN(generator,discriminator,opt)\n",
    "\n",
    "\n",
    "### import noise\n",
    "noise = pd.read_csv('submission/noise.csv',index_col=0)\n",
    "noise = noise.values\n",
    "synthetic_data = generator.model.predict(noise)\n",
    "synthetic_data = pd.DataFrame(synthetic_data,columns = df_train.columns) /100\n",
    "synthetic_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
